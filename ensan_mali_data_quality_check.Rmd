---
title: "Enquête Nationale sur la Sécurité Alimentaire et Nutritionnelle - Septembre 2022"
subtitle : "Rapport de suivi journalier de la collecte"
author: "Comité Technique ENSAN "
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: word_document
toc: true 
  toc_depth: 5
editor_options: 
  chunk_output_type: inline
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F, warning = F,  fig.width=10, fig.height=10, 
                      tab.topcaption=TRUE, ft.align="center",
                      tab.cap.pre = "Tableau ", message = F)

library(tidyverse)
library(haven)
library(labelled)
library(plotly)
library(rstatix)
library(kableExtra)
library(lubridate)
library(DT)
library(flextable)
library(readxl)
library(RColorBrewer)
library(sjlabelled)

```

```{r utilitaires}
mise_en_forme <- function(tableau, ...) {
  
  options(digits=2)
  
big_border = fp_border_default(color="black", width = 2)
small_border = fp_border_default(color="#0080FF80", width = 1)
 
#Ajouter la partie sur l'ensemble
  flextable(tableau) %>% 
  colformat_num(big.mark=" ", decimal.mark = ",") %>% 
    color(i = 1, color = "white", part = "header") %>% 
    bg(bg = "#000000", part = "header") %>%
    bold(j = 1, bold = TRUE, part = "all") %>% 
    bold(j = 1, bold = TRUE, part = "all") %>% 
    border_inner_h(part="all", border = small_border ) %>%
    border_inner_v(part="all", border = small_border ) %>% 
    border_outer(part="all", border = big_border )%>%
    align(align = "center", part = "all") %>%
    valign(valign = "center", part = "all") %>%
    align(j = 1, align = "left", part = "all") %>%
    line_spacing(space = 1, part = "all") %>%
    padding(padding = 2, part = "all") %>% 
    font(fontname = "Times New Roman", part = "all") %>% 
    fontsize(size = 9, part = "body") %>% 
    autofit(add_w = 0.01, add_h = 0.01, part = c("body", "header"),
            unit = "mm", hspans = "none")
  
}

#Personnaliser les thèmes
theme_custom <- function() {
  theme_bw() +
    theme(
      plot.title = element_text(size = 10, face = "bold", hjust = .5,
                                margin = margin(t = 5, b = 15),
                                colour = "#0080FF80"),
      panel.border = element_rect(colour = "#0080FF80"),
      panel.grid.major = element_line(colour = "#0080FF80"),
      panel.grid.minor = element_blank(),
      legend.title = element_text(size = 9, face = "bold"),
      legend.text = element_text(size = 9),
      axis.text = element_text(size = 9),
      axis.title= element_blank(), 
      legend.position = "bottom",
      axis.text.y = element_blank()
    )
}

tableau_c <- function(var_ligne, var_col, poids){
  df <- tibble(var_ligne, var_col, poids)
  tab1 <- df %>% 
  select(var_col, poids) %>% 
  sjlabelled::as_label() %>% 
  group_by(var_col) %>% 
  summarise(effectif = sum(poids)) %>% 
  mutate(var_ligne = as_factor("Ensemble"), .before = 1)

tab <- df %>% 
  select(var_ligne, var_col, poids) %>% 
   sjlabelled::as_label() %>%
  group_by(var_ligne, var_col) %>% 
  summarise(effectif = sum(poids)) %>% 
  bind_rows(tab1) %>% 
  group_by(var_ligne) %>% 
  mutate(pct = round(100 * effectif / sum(effectif),1)) %>% 
  select(var_ligne, var_col, pct) 

return(tab)
}

#Tableau de contingence
cross_tab <- function(var_ligne, var_col, poids){
  
  df <- tibble(var_ligne, var_col, poids)
  
  #Obtenir le tableau de contingence
  tab <- tableau_c(var_ligne, var_col, poids)
  
  names(tab)[1] <- get_label(df$var_ligne)
 
  #Agréger suivant la variable en ligne  
tab <- tab %>% 
  pivot_wider(names_from = var_col, 
              values_from = pct, values_fill = 0) 
 
#Sortie
mise_en_forme(tab)
}

#Création d'une fonction permettant d'inclure dans le rapport le résumé stats d'une variable quantitative.
stat_desc <- function(var_ligne, var_col, poids){
  df <- tibble(var_ligne, var_col, poids)
  
 
  #Statistiques descriptives sur l'ensemble de la base
  
  tab <- df %>% select(var_col, poids) %>% 
    summarise(n = sum(!is.na(var_col), na.rm = T),
              moyenne = wtd.mean(x = var_col, weights = poids, normwt = T,
                                 na.rm = TRUE),
              mediane = wtd.quantile(var_col, weights = poids, probs = 0.5,
                                     normwt = T, na.rm = T),
    ecart.type = sqrt(wtd.var(var_col, weights = var_col, normwt = T,
                              na.rm = T)),
    minimum = min(var_col, na.rm = T),
    maximum = max(var_col, na.rm = T)) %>% 
  mutate(var_ligne = as_factor("Ensemble"), .before = 1)
     
  #Statistiques descriptives par catégories
  res <- df %>% as_label() %>% 
    group_by(var_ligne) %>%
    summarise(n = sum(!is.na(var_col), na.rm = T),
              moyenne = wtd.mean(x = var_col, weights = poids, normwt = T,
                                 na.rm = TRUE),
              mediane = wtd.quantile(var_col, weights = poids, probs = 0.5,
                                     normwt = T, na.rm = T),
    ecart.type = sqrt(wtd.var(var_col, weights = var_col, normwt = T,
                              na.rm = T)),
    minimum = min(var_col, na.rm = T),
    maximum = max(var_col, na.rm = T)) %>%
    bind_rows(tab) 
  
  
  
   #Noms des variables du tableau
  colnames(res) <- c(get_label(df$var_ligne), names(res)[2:7])
  
  mise_en_forme(res)
}


```


```{r data, include=FALSE}
#set working directory
setwd("C:/RAM/Datasets/ENSAN_SEPT2021")


#importer les fichiers de données spss contenues dans le dossier
files <- list.files(pattern="\\.sav$")
df_list <- map(files, read_sav)
names(df_list) <- str_remove(files, "\\.sav$")

#Enlever les extensions .sav du nom des fichiers
names(df_list) <- str_remove(files, ".sav$")


#Rendre les bases disponibles dans l'environnement de travail global
list2env(df_list, .GlobalEnv)

#Renommer certaines variables
dta_mng <-  dta_mng %>%
  select(start:id_menage) %>% 
  mutate(EnumName = as.character(q18_code_enqueteur))%>% 
  separate(`@_submission_time`, c("Survey_date", "survey_hour"), 
           sep = " ") %>% 
  mutate(Survey_date = as.Date(Survey_date),
         debut = str_sub(start, start = 1L, end = 10L),
         debut = as.Date(debut),
         duree_envoi = difftime(Survey_date, debut, units = "days"),
         duree_envoi = as_numeric(duree_envoi)) 
  

submission_mng <- dta_mng %>% group_by(Survey_date) %>% 
  summarise(menage = n())
```

```{r}
#Importer les bases au format xlsx
files <- c("list_enqtr.xlsx", "list_equipe.xlsx")
df_list <- map(files, read_xlsx)

names(df_list) <- str_remove(files, "\\.xlsx$")

names(df_list) <- str_remove(files, ".xlsx$")
list2env(df_list, .GlobalEnv)

#Liste des équipes
list_equipe <- list_equipe %>% 
  rename(q18_code_equipe =q18_code_equipe) %>% 
  select(q18_code_equipe, echantillon=Nb_menage)

#Liste des enquêteurs
list_enqtr <- list_enqtr %>% 
  select(EnumName = CODE, nom_enqtr = `PRENOMS ET NOMS`,
         telephone = TELEPHONE)
  
```


## Avancée de la collecte des données

### Données envoyées sur le serveur

```{r fig.height= 6, fig.cap="Evolution journalière des envois de données"}
#Survey Progress
# submissions
dta_anthropo <- dta_anthropo %>% 
  separate(`@_submission_time`, c("Survey_date", "survey_hour"), 
           sep = " ") %>% 
  mutate(Survey_date = as.Date(Survey_date),
         debut = str_sub(TimeStartRecorded, start = 1L, end = 10L),
         debut = as.Date(debut),
         duree_envoi = difftime(Survey_date, debut, units = "days"),
         duree_envoi = as_numeric(duree_envoi))

#Evolution journalière du nombre d'envoi
dta_anthropo %>% 
  group_by(Survey_date) %>% 
  summarise(anthropo = n()) %>%
  select(Survey_date, anthropo) %>% 
  full_join(submission_mng) %>% 
  replace_na(list(anthropo = 0, menage = 0)) %>% 
  pivot_longer(-Survey_date) %>%
  ggplot(aes(x = Survey_date, y = value, group = name)) +
  geom_line(aes(color = name), size = 1) +
  geom_point(aes(color = name), size = 2) +
  geom_text(aes(label = value),
    nudge_x = 0.25,
    nudge_y = 0.25,
    check_overlap = TRUE,
    size = 3, fontface = 2) +
    labs(title = "Nombre de questionnaires envoyés par jour") +
  theme_custom()
```

### Durée moyenne entre le début de la collecte et l'envoi sur le serveur

```{r, fig.cap="Durée moyenne d'envoi des données par équipe"}
#Nombre d'observations par questionnaires et par cercle.
#Questionnaire ménage
nb_menage <- dta_mng %>%  
  dplyr::select(q12_nom_cercle, q18_code_equipe, duree_envoi) %>% 
  dplyr::group_by(q18_code_equipe) %>% 
  mutate(menage = n(),
        duree_envoi = round(mean(duree_envoi, na.rm = T), 1)) %>%
  ungroup() %>%
  dplyr::group_by(q12_nom_cercle, q18_code_equipe) %>% 
  slice(1) %>% ungroup() %>%
  left_join(list_equipe) %>% 
  mutate(tx_realisation = round(100 * menage/echantillon, 1)) %>% 
  set_value_labels() %>% as_label()

#Nombre de ménages enquêtés pour le questionnaire anthropo  
nb_anthropo <- dta_anthropo %>%  
  dplyr::group_by(q12_nom_cercle, q18_code_equipe) %>% 
  summarise(anthropo = n()) %>% ungroup() %>% 
  set_value_labels() %>% as_label()

#Nombre de fefa
nb_fefa <- dta_fefa %>% 
  dplyr::group_by(q12_nom_cercle, q18_code_equipe) %>% 
  summarise(fefa = n()) %>% 
  set_value_labels() %>% as_label()

#Nombre d'enfants de moins de 5 ans
nb_enft <- dta_enft %>% 
  dplyr::group_by(q12_nom_cercle, q18_code_equipe) %>% 
  summarise(child_u5 = n()) %>% 
  set_value_labels() %>% as_label()

#Fusionner les différentes bases
pdi <- c("PDI SEGOU", "PDI MOPTI", "PDI TOMBOUCTOU", 
         "PDI GAO", "PDI MENAKA", "PDI BAMAKO")

nb_obs <- full_join(nb_menage, nb_anthropo) %>% 
  full_join(nb_fefa) %>% 
  full_join(nb_enft) %>% 
  filter(!q18_code_equipe %in% pdi)

#Durée moyenne d'envoi des données
nb_obs %>% 
mutate(q18_code_equipe = fct_reorder(q18_code_equipe, duree_envoi,
                                     .desc = TRUE)) %>%
  ggplot(aes(x = q18_code_equipe, y = duree_envoi)) + 
  geom_bar(stat = "identity", fill = "steel blue") +
  geom_text(aes(y = duree_envoi, label = duree_envoi), hjust = -.1) +
  labs(x = "Equipe",
       y = "Nombre de jours",
       title = "Durée moyenne d'envoi des données (en jours)",
       caption = "Données: ENSAN-Septembre 2022") +
  coord_flip() +
  theme_bw()
```

### Liste des équipes qui n'ont pas du tout envoyé de données

**Jusqu'à cette date, les équipes qui suivent n'ont pas encore envoyé de données sur le serveur. Les coordinateurs régionaux concernés sont priés de prendre les dispositions qui s'imposent**

```{r, tab.cap="Liste des équipes n'ayant pas envoyé de données sur le serveur"}
dta_mng %>%  
  dplyr::select(q18_code_equipe) %>% 
  dplyr::group_by(q18_code_equipe) %>% 
  count() %>% ungroup() %>% 
  right_join(list_equipe) %>%
  mutate(EnumName = q18_code_equipe*10 + 1) %>% 
  left_join(list_enqtr) %>% 
  mutate(telephone = as_factor(telephone)) %>% to_label() %>% 
  select(q18_code_equipe, chef_equipe = nom_enqtr, telephone) %>% 
 filter(is.na(n)) %>% 
  mise_en_forme()
  
```


### Nombre de questionnaires par équipe


```{r fig.height= 8, fig.cap="Nombre de questionnaires par types"}
nb_obs %>% select(-c(q12_nom_cercle, duree_envoi, echantillon, 
                     tx_realisation)) %>%
  pivot_longer(-q18_code_equipe) %>%
  mutate(name = factor(name, levels = c("menage", "anthropo",
                                        "fefa", "child_u5"), ordered = T)) %>% 
  group_by(q18_code_equipe) %>%
  arrange(q18_code_equipe, desc(name)) %>%
  mutate(lab_ypos = cumsum(value) - 0.5 * value) %>% ungroup() %>% 
  ggplot(aes(x = q18_code_equipe, y = value)) +
    geom_col(aes(fill = name), width = 0.7)+
    geom_text(aes(y = lab_ypos, label = value, group =name), color = "white") +
  scale_fill_manual(values = c("#228833", "#0073C2FF", "#EFC000FF", "#EE6677")) +
    labs(title = "Nombre de questionnaires envoyés") +
   coord_flip() +
  theme_bw()
```

```{r, tab.cap="Nombre de questionnaires par types"}
nb_obs %>% select(-c(duree_envoi, echantillon, tx_realisation)) %>% 
  mise_en_forme()
```

### Nombre de ménages enquêtés en pourcentage du nombre prévu par équipe

```{r, fig.cap="Pourcentage de ménages enquêtés par équipe"}
ggplot(nb_obs, aes(x = q18_code_equipe, y = tx_realisation)) + 
  geom_bar(stat = "identity", fill = "steel blue") +
  geom_text(aes(y = tx_realisation, label = tx_realisation), hjust = -.1) +
  expand_limits(y = c(0, 100)) +
  scale_y_continuous(breaks = seq(0, 100, by = 10), labels = abs) + 
  labs(x = "Equipe",
       y = "Pourcentage de ménages enquêtés",
       title = "Pourcentage de ménages enquêtés par équipe",
       caption = "Données: ENSAN-Septembre 2022") +
  coord_flip() +
  theme_bw()
```

### Nombre de ménages enquêtés en pourcentage du nombre prévu par cercle

```{r, fig.cap="Pourcentage de ménages enquêtés par cercle"}
nb_obs %>% 
  dplyr::group_by(q12_nom_cercle) %>% 
  summarise(menag = sum(menage, na.rm=T),
            echant = sum(echantillon, na.rm=T)) %>% 
  mutate(tx_realisation = round(100 * menag/echant, 1)) %>% 
  ggplot(aes(x = q12_nom_cercle, y = tx_realisation)) + 
  geom_bar(stat = "identity", fill = "steel blue") +
  geom_text(aes(y = tx_realisation, label = tx_realisation), hjust = -.1) +
  expand_limits(y = c(0, 100)) +
  scale_y_continuous(breaks = seq(0, 100, by = 10), labels = abs) + 
  labs(x = "Cercle",
       y = "Pourcentage de ménages enquêtés",
       title = "Pourcentage de ménages enquêtés par équipe",
       caption = "Données: ENSAN-Septembre 2022") +
  coord_flip() +
  theme_bw()
```
```{r eval=F}
list_enqtr <- mutate(list_enqtr, EnumName = as.character(EnumName))
```


## Food Consumption Score (FCS) / Food Consumption Groups (FCG)

### Food Consumption Groups by Admin1 

```{r}
ggplotly(FCGadm1_barplot)
```

### Food Consumption Groups by Admin2

```{r}
ggplotly(FCGadm2_barplot)
```

### Food Consumption Groups by Admin1 and Enumerator

```{r}
ggplotly(FCGadm1EnumName_barplot)
```

### Boxplot of median FCS by enumerator

```{r}
ggplotly(FCSEnumNamebox)
```

### Tableau of enumerators with outlier median FCS

```{r}
FCSOutliertable %>% arrange(desc(FCS_median)) %>% kbl() %>%  kable_styling()
```

### Cereal
```{r}
cereal <- dataset %>% filter(FCSStap <= 4) %>% select(ADMIN2Name, Community,HHID,TeamLeaderID, EnumName,FCSStap,FCSVeg, Survey_date) 

datatable(cereal, rownames = FALSE, filter = "top")

```

### Cereal and vegetable and Dairy

```{r}
tabcerealelegumelait <- dataset %>% filter(FCSStap <= 4) %>% select(ADMIN2Name, Community,HHID,TeamLeaderID, EnumName,FCSStap,FCSVeg,FCSDairy, Survey_date) 

datatable(tabcerealelegumelait, rownames = FALSE, filter = "top")

```

### vegetable
```{r}
legumefeuille <- dataset %>% filter(FCSVeg <= 3) %>% select(ADMIN2Name, Community,HHID,TeamLeaderID, EnumName,FCSVeg, Survey_date)

datatable(legumefeuille, rownames = FALSE, filter = "top")


```


## Household Dietary Diversity Score (HDDS)

### HDDS phases by Admin1 

```{r}
ggplotly(HDDSadm1_barplot)
```

### HDDS phases by Admin2 

```{r}
ggplotly(HDDSadm2_barplot)
```

### HDDS phases by Admin1 and Enumerator

```{r}
ggplotly(HDDSadm1EnumName_barplot)
```

## reduced Coping Strategy Index (rCSI)

### rCSI (CH phases) by Admin1 

```{r}
ggplotly(rCSIadm1_barplot)
```

### rCSI (CH phases) by Admin2 

```{r}
ggplotly(rCSIadm2_barplot)
```


### rCSI (CH phases) by Admin1 and Enumerator

```{r}
ggplotly(rCSIadm1EnumName_barplot)
```


### Boxplot of median rCSI score 

```{r}
ggplotly(rcsiEnumNamebox)
```

### Table of enumerators with outlier median rcsi

```{r}
rcsiOutliertable %>% arrange(desc(rcsi_median)) %>% kbl() %>%  kable_styling()
```


## Household Hunger Scale (HHS)

### HHS (CH phases) by Admin1 

```{r}
ggplotly(HHSadm1_barplot)
```

### HHS (CH phases) by Admin2 

```{r}
ggplotly(HHSadm2_barplot)
```

### HHS (CH phases) by Admin1 and Enumerator

```{r}
ggplotly(HHSadm1EnumName_barplot)
```


## Livelihood Coping Strategies (LhCS)

### Livelihood Coping Strategies by Admin1 

```{r}
ggplotly(LHCSadm1_barplot)
```


### Livelihood Coping Strategies by Admin2 

```{r}
ggplotly(LHCSadm2_barplot)
```


### Livelihood Coping Strategies by Admin1 and Enumerator

```{r}
ggplotly(LHCSadm1EnumName_barplot)
```

Ajouter une section sur la dépense des ménages et faire des contrôles par rapport aux dépenses faibles (moins que la valeur du 5e percentile de l'enquête précédente) et détecter les enquêteurs qui ne renseignent pas du tout les dépenses non alimentaires.